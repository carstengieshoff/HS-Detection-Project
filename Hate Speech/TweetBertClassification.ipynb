{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "TweetBertClassification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtqo-KADGG67"
      },
      "source": [
        "# Building a BERTweet-Classifier for Hatespeech Classification\n",
        "\n",
        "In this notebook we build a hate speech classifier based on the data presented in 'Automated Hate Speech Detection and the Problem of Offensive Language\u0003' by Davison et al. in 2ß18. The classifier consists of a fully connected layer ont top of a BERTweet model.\n",
        "\n",
        "The following is based on:\n",
        "- https://curiousily.com/posts/sentiment-analysis-with-bert-and-hugging-face-using-pytorch-and-python/\n",
        "- https://xiangyutang2.github.io/tweet-classification/\n",
        "- https://github.com/t-davidson/hate-speech-and-offensive-language\n",
        "- https://github.com/VinAIResearch/BERTweet\n",
        "- https://huggingface.co/vinai/bertweet-base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuoFPdzvGG7C"
      },
      "source": [
        "## Loading all needed Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmNuCOFOGh1w",
        "outputId": "0428ba94-4310-4e7e-8f86-4bba85771248"
      },
      "source": [
        "! git clone https://github.com/huggingface/transformers.git\n",
        "! cd transformers\n",
        "! pip3 install --upgrade transformers\n",
        "! pip3 install emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'transformers' already exists and is not an empty directory.\n",
            "Requirement already up-to-date: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n",
            "Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.2)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CEqGmlAVGG7C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f730edfa-99cc-46b6-8e9b-9671d22541a2"
      },
      "source": [
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, AutoModel, AutoTokenizer \n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from torch import nn, optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import re\n",
        "from sklearn.utils import resample\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#from classifier import *\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgxcMFe9glxh"
      },
      "source": [
        "- Get GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Iaamld2dMNRj",
        "outputId": "bcbdd68a-2498-490e-fec9-8939321ddd4a"
      },
      "source": [
        "# Get Device \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Used device is {device}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Used device is cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CGRFu1l7gcFg"
      },
      "source": [
        "- Next we create two folders to save models and data in \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8FPxnuxwf5Ru",
        "outputId": "d36370c6-b94a-44fb-adbc-ba7338ae85c2"
      },
      "source": [
        "# Setting up folder to save data and models\n",
        "! mkdir data\n",
        "! mkdir models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "mkdir: cannot create directory ‘models’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTfXhl9tMXpY"
      },
      "source": [
        "## Data Exploration and Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmHj0IvGfr31"
      },
      "source": [
        "- Upload data in csv format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "Uk43eKrfMXpc",
        "outputId": "eaaa7807-ed4a-4937-aa1c-b8a4958d535c"
      },
      "source": [
        "# Loading Data \n",
        "df = pd.read_csv(\"labeled_data.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  count  ...  class                                              tweet\n",
              "0           0      3  ...      2  !!! RT @mayasolovely: As a woman you shouldn't...\n",
              "1           1      3  ...      1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...\n",
              "2           2      3  ...      1  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...\n",
              "3           3      3  ...      1  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...\n",
              "4           4      6  ...      1  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "fB0-oTXEMXpd",
        "outputId": "21f12133-2ccc-4217-87a2-55a149700a5a"
      },
      "source": [
        "# Data class distributions\n",
        "df['class'].hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f65d81b81d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "seFV5ouZgsW8"
      },
      "source": [
        " - We slightly alter prerpocess fucntion from origianl code. Using casual tokenizer from nltk does eitehr keep or remove handles/URLs completely\n",
        " We aim to have mentions and links as information for the model. However, as no metadata about users is used, it does not matter who is addressed.\n",
        " Thus, replacing all handles and URLs by respective representations will help the model understand better if someone was addressed or not. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz6UHl4vGszd"
      },
      "source": [
        "def anonymize_users_and_links(text_string):\n",
        "    \"\"\"\n",
        "    Accepts a text string and replaces:\n",
        "    1) urls with URLHERE\n",
        "    2) lots of whitespace with one instance\n",
        "    3) mentions with MENTIONHERE\n",
        "\n",
        "    This allows us to get standardized counts of urls and mentions\n",
        "    Without caring about specific people mentioned\n",
        "    \"\"\"\n",
        "    space_pattern = '\\s+'\n",
        "    giant_url_regex = ('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|'\n",
        "        '[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "    mention_regex = '@[\\w\\-]+'\n",
        "    parsed_text = re.sub(space_pattern, ' ', text_string)\n",
        "    parsed_text = re.sub(giant_url_regex, 'URL', parsed_text)\n",
        "    parsed_text = re.sub(mention_regex, 'USER', parsed_text)\n",
        "    parsed_text = re.sub('RT', '', parsed_text)\n",
        "    #parsed_text = parsed_text.code(\"utf-8\", errors='ignore')\n",
        "    return parsed_text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "rqtZFR1tMXpe",
        "outputId": "358efb7b-e811-47de-8347-fa1f74685f24"
      },
      "source": [
        "# Processing Tweets\n",
        "df['tweet'] = [anonymize_users_and_links(tweet) for tweet in df['tweet']]\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>count</th>\n",
              "      <th>hate_speech</th>\n",
              "      <th>offensive_language</th>\n",
              "      <th>neither</th>\n",
              "      <th>class</th>\n",
              "      <th>tweet</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>!!!  USER: As a woman you shouldn't complain a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!  USER: boy dats cold...tyga dwn bad for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!  USER Dawg!!!!  USER: You ever fuck a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!  USER: USER she look like a tranny</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>!!!!!!!!!!!!!  USER: The shit you hear about m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  count  ...  class                                              tweet\n",
              "0           0      3  ...      2  !!!  USER: As a woman you shouldn't complain a...\n",
              "1           1      3  ...      1  !!!!!  USER: boy dats cold...tyga dwn bad for ...\n",
              "2           2      3  ...      1  !!!!!!!  USER Dawg!!!!  USER: You ever fuck a ...\n",
              "3           3      3  ...      1       !!!!!!!!!  USER: USER she look like a tranny\n",
              "4           4      6  ...      1  !!!!!!!!!!!!!  USER: The shit you hear about m...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu02Y_WfGG7K"
      },
      "source": [
        "## Building Bert Classifier Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y1fiKVdnGG7L"
      },
      "source": [
        "### Bert specific processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qfK5p4QGG7L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6164f8c0-7902-4b91-edd1-a8906c7633ae"
      },
      "source": [
        "# Here we load a BERTweet specific tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bertweet-base\", use_fast=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Special tokens have been added in the vocabulary, make sure the associated word embedding are fine-tuned or trained.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrbiImoZj4C1"
      },
      "source": [
        "- Get understanding of the distribution of token sizes for maximal lanrgth used in BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jFQ-dakGQy2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "697af06b-8196-49c5-ca18-cc82ea8fc7cd"
      },
      "source": [
        "df['len'] = [len(tokenizer.tokenize(tweet)) for tweet in df['tweet']]\n",
        "df['len'].hist() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f64137a2b50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q1xDxi2TGG7M"
      },
      "source": [
        "### Build PyTorch dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5iRZUrDGG7M"
      },
      "source": [
        "# Data Structure\n",
        "class TweetsDataset(Dataset):\n",
        "    def __init__(self, tweets, labels, tokenizer, max_len):\n",
        "        self.tweets = tweets\n",
        "        self.labels = labels\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.tweets)\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        \n",
        "        tweet = str(self.tweets[item])\n",
        "        label = self.labels[item]\n",
        "        \n",
        "        encoding = tokenizer(tweet,\n",
        "                             truncation=True,\n",
        "                             add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n",
        "                             return_token_type_ids=False,\n",
        "                             padding = 'max_length',\n",
        "                             max_length=self.max_len,\n",
        "                             return_attention_mask=True,\n",
        "                             return_tensors='pt')\n",
        "        \n",
        "        return { 'tweet': tweet, 'input_ids': encoding['input_ids'].flatten(),\n",
        "          'attention_mask': encoding['attention_mask'].flatten(),\n",
        "          'label': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "# Data Loader\n",
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "    ds = TweetsDataset(\n",
        "        tweets=df['tweet'].to_numpy(),\n",
        "        labels=df['class'].to_numpy(),\n",
        "        tokenizer=tokenizer,\n",
        "        max_len=max_len\n",
        "    )\n",
        "    return DataLoader(\n",
        "        ds,\n",
        "        batch_size=batch_size,\n",
        "        num_workers=2\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-AWbwUqGG7O"
      },
      "source": [
        "### Actual Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_DvWra9GG7O"
      },
      "source": [
        "class HSClassifier(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        \n",
        "        super(HSClassifier, self).__init__()\n",
        "        self.bert = AutoModel.from_pretrained(\"vinai/bertweet-base\")\n",
        "        self.drop = nn.Dropout(p=0.3)\n",
        "        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
        "        output = self.drop(pooled_output)\n",
        "        return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIyj-PWKGG7P"
      },
      "source": [
        "## Training the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WeVa1TidGG7P"
      },
      "source": [
        "### Define Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Frpt7_9lxxiv"
      },
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  names=['Hate','Offensive','Neither']\n",
        "  confusion_df = pd.DataFrame(cm, index=names,columns=names)\n",
        "  plt.figure(figsize=(5,5))\n",
        "  sns.heatmap(confusion_df,annot=True,annot_kws={\"size\": 12},cmap='gist_gray_r',cbar=False, square=True,fmt='.2f')\n",
        "  plt.ylabel(r'True categories',fontsize=14)\n",
        "  plt.xlabel(r'Predicted categories',fontsize=14)\n",
        "  plt.tick_params(labelsize=12)\n",
        "  plt.savefig(f'/content/gdrive/My Drive/HS/data/{NAME}_exp{EXPONENT}_epochs{EPOCHS}_Batchsize{BATCH_SIZE}_confusionmatrix.png')\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOtgFHQQyLgS"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  # put to eval mode to disable dropout \n",
        "  model = model.eval()\n",
        "\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      labels = d[\"label\"].to(device)\n",
        "\n",
        "      outputs = model(input_ids=input_ids, attention_mask=attention_mask) #dim BATCH_SIZE x 3\n",
        "      # torch.max(outputs, dim=1) returns (vals, positions) of maxima -> positions are kept and correspond to class labels\n",
        "      _, preds = torch.max(outputs, dim=1) # dim BATCH_SIZE x 1\n",
        "\n",
        "      predictions.extend(preds)\n",
        "      #prediction_probs.extend(outputs)\n",
        "      real_values.extend(labels)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  #prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return predictions, real_values #prediction_probs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mw1k970NGG7P"
      },
      "source": [
        "def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
        "    \n",
        "    model = model.train()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    \n",
        "    show_every = np.floor(len(data_loader)/5)\n",
        "    \n",
        "    for i,d in enumerate(data_loader):\n",
        "        \n",
        "        input_ids = d[\"input_ids\"].to(device)\n",
        "        attention_mask = d[\"attention_mask\"].to(device)\n",
        "        labels = d[\"label\"].to(device)\n",
        "        \n",
        "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        # torch.max(outputs, dim=1) returns (vals, positions) of maxima -> positions are kept and correspond to class labels\n",
        "        _, preds = torch.max(outputs, dim=1)\n",
        "        \n",
        "        loss = loss_fn(outputs, labels) # both outputs and labels are in {0,1,2}\n",
        "        correct_predictions += torch.sum(preds == labels)\n",
        "        \n",
        "        losses.append(loss.item())\n",
        "        loss.backward()\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "                \n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqkdAEHUGG7Q"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "    \n",
        "    model = model.eval()\n",
        "    losses = []\n",
        "    correct_predictions = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for d in data_loader:\n",
        "            \n",
        "            input_ids = d[\"input_ids\"].to(device)\n",
        "            attention_mask = d[\"attention_mask\"].to(device)\n",
        "            labels = d[\"label\"].to(device)\n",
        "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
        "            _, preds = torch.max(outputs, dim=1)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            correct_predictions += torch.sum(preds == labels)\n",
        "            losses.append(loss.item())\n",
        "            \n",
        "    return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWO18hpyvXyT"
      },
      "source": [
        "def get_weights(df, exponent = 1):\n",
        "    # original balanced weights\n",
        "    class_weights_balanced = dict(zip([0,1,2],[len(df)/(3*sum(df['class']==i)) for i in range(3)]))\n",
        "\n",
        "    # Expoentially weighted\n",
        "    Z = sum(val**exponent for key,val in class_weights_balanced.items())\n",
        "    class_weights_dict= dict(zip([0,1,2],[(val**exponent)/Z for key,val in class_weights_balanced.items()]))\n",
        "\n",
        "    # To tensor\n",
        "    class_weights = torch.tensor([ value for value in class_weights_dict.values()]) \n",
        "\n",
        "    return class_weights "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGaZ6wceKQTr"
      },
      "source": [
        "### Parameter choices\n",
        "- Set hyper parameters and run optimization accordingly"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGa0sP8RKA9F"
      },
      "source": [
        "MAX_LEN = 100 # chosen acccroding to hist above\n",
        "BATCH_SIZE = 64 # tunable hyper parameter\n",
        "EPOCHS = 4\n",
        "EXPONENT = 1\n",
        "lr = 2e-5\n",
        "NAME ='BERTweet'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dACk_YZ3GG7Q"
      },
      "source": [
        "### Optimization "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O72MpM9eKDwC"
      },
      "source": [
        "- Prepare data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVZwjxDvGG7N"
      },
      "source": [
        "# Splitting data\n",
        "df_train, df_test = train_test_split(df, test_size=0.2, random_state = 42) \n",
        "df_val, df_test = train_test_split(df_test, test_size=0.5,random_state = 42) \n",
        "\n",
        "# Create DataLoaders\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8g1hTd_EJAT"
      },
      "source": [
        "- Initialize model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB0rZZCzGG7O"
      },
      "source": [
        "# Initialize model\n",
        "model = HSClassifier(3).to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o52yRNpbD362"
      },
      "source": [
        "- Set everything optimization related\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4aUFbTlNlMM",
        "outputId": "14e57e7a-b39e-4a87-ca62-d7499d2bd4c0"
      },
      "source": [
        "#Optimizer & Scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=lr, correct_bias=False)\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps= len(train_data_loader) * EPOCHS\n",
        ")\n",
        "\n",
        "#Weights \n",
        "class_weights = get_weights(df_train, exponent=EXPONENT)\n",
        "print('Class weights: ', class_weights)\n",
        "\n",
        "# The choice of loss is done, as 'This criterion combines LogSoftmax and NLLLoss in one single class'. \n",
        "# given input vector softmay is applied, and then NLLL  loss performed\n",
        "loss_fn = nn.CrossEntropyLoss(weight = class_weights).to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Class weights:  tensor([0.7058, 0.0524, 0.2418])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMDv-TNhEMbT"
      },
      "source": [
        "- Actual optimization procedure"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "GiCAaHDGNlMO",
        "outputId": "04fc2b8c-f8e7-41aa-830c-451dafc0c9dc"
      },
      "source": [
        "%%time\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "    print('-' * 10)\n",
        "    train_acc, train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer, device, scheduler, len(df_train))\n",
        "      \n",
        "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "    val_acc, val_loss = eval_model(model, val_data_loader, loss_fn, device, len(df_val))\n",
        "      \n",
        "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "    print()\n",
        "    \n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "    \n",
        "    if val_acc > best_accuracy:\n",
        "        print(f'Model updated after epoch: {epoch+1} \\n')\n",
        "        torch.save(model.state_dict(), f'models/{NAME}_exp{EXPONENT}_epochs{EPOCHS}_BatchSize{BATCH_SIZE}_best_model_state.bin')\n",
        "        best_accuracy = val_acc\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-98c7d42f694d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history = defaultdict(list)\\nbest_accuracy = 0\\n\\nfor epoch in range(EPOCHS):\\n    print(f'Epoch {epoch + 1}/{EPOCHS}')\\n    print('-' * 10)\\n    train_acc, train_loss = train_epoch(model, train_data_loader, loss_fn, optimizer, device, scheduler, len(df_train))\\n      \\n    print(f'Train loss {train_loss} accuracy {train_acc}')\\n    val_acc, val_loss = eval_model(model, val_data_loader, loss_fn, device, len(df_val))\\n      \\n    print(f'Val   loss {val_loss} accuracy {val_acc}')\\n    print()\\n    \\n    history['train_acc'].append(train_acc)\\n    history['train_loss'].append(train_loss)\\n    history['val_acc'].append(val_acc)\\n    history['val_loss'].append(val_loss)\\n    \\n    if val_acc > best_accuracy:\\n        print(f'Model updated after epoch: {epoch+1} \\\\n')\\n        torch.save(model.state_dict(), f'models/{NAME}_exp{EXPONENT}_epochs{EPOCHS}_BatchSize{BATCH_SIZE}_best_model_state.bin')\\n        best_accuracy = val_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-84-053aebf34bca>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mcorrect_predictions\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD8UaE6kNlMP"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIOMi1PlNlMP"
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1])\n",
        "#plt.yscale('log')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oq_PdVG3BUNZ"
      },
      "source": [
        "- Next we load our best model, as the current state might have overfitted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wudQ6QS1BTmO"
      },
      "source": [
        "# load best model from optimization\n",
        "model = HSClassifier(3)\n",
        "model.load_state_dict(torch.load(f'models/{NAME}_exp{EXPONENT}_epochs{EPOCHS}_BatchSize{BATCH_SIZE}_best_model_state.bin'))\n",
        "model = model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rcl-b5dlNlMQ"
      },
      "source": [
        "# Test Accuracy\n",
        "test_acc, _ = eval_model(model, test_data_loader, loss_fn, device, len(df_test))\n",
        "print(f'Test Accuracy: {test_acc.item()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hYSixO-LAB3"
      },
      "source": [
        "- Calculate Scores "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQp-OLKsNlMQ"
      },
      "source": [
        "# Calculation of relevant scores\n",
        "y_pred, y_test = get_predictions(model, test_data_loader)\n",
        "report = classification_report(y_test, y_pred, target_names=['HS', 'OL', 'NE'], output_dict=True)\n",
        "report_df = pd.DataFrame(report).transpose()\n",
        "report_df.to_csv(f'/content/gdrive/My Drive/HS/data/{NAME}_exp{EXPONENT}_epochs{EPOCHS}_BatchSize{BATCH_SIZE}_Report.csv') \n",
        "\n",
        "report_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_BmI-JWNlMQ"
      },
      "source": [
        "cm = confusion_matrix(y_test, y_pred, normalize = 'true')\n",
        "show_confusion_matrix(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jS8qrdiUNlMR"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"data\")\n",
        "files.download(\"models\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCcPBuN431Qt"
      },
      "source": [
        "model_save_name = f'models/{NAME}_exp{EXPONENT}_epochs{EPOCHS}_BatchSize{BATCH_SIZE}_best_model_state.bin'\n",
        "path = f\"/content/gdrive/My Drive/HS/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxGcckG-0d0q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}